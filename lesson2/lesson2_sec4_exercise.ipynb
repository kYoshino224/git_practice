{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson2 畳み込みニューラルネットワーク (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "- Section1 解説\n",
    "  - 1.1 CNN基礎\n",
    "  - 1.2 Convolution(畳み込み)層\n",
    "  - 1.3 Pooling(プーリング)層\n",
    "  - 1.4 確認問題\n",
    "- Section2 実装①\n",
    "  - 2.1 Fasion MNISTをCNNでクラス分類\n",
    "  - 2.2 CIFAR10のデータをCNNでクラス分類\n",
    "- Section3 テクニック・発展内容\n",
    "  - 3.1 Data Augmentation\n",
    "  - 3.2 画像データの正規化\n",
    "  - 3.3 Batch Normalization\n",
    "  - 3.4 Skip Connection  (Residual Network)\n",
    "  - 3.5 学習済みネットワークの利用\n",
    "  - 3.6 学習させたモデルの保存・再利用\n",
    "  - 3.7 確認問題\n",
    "- Section4 実装②\n",
    "  - 4.1 CIFAR10のデータをCNNでクラス分類②\n",
    "- Section5 ケーススタディ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 の解答\n",
    "\n",
    "問1: ② 問2: ① 問3: ① 問4: ①"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 22:16:50.820911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.python.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section4 実装②"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CIFAR10のデータをCNNでクラス分類②"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "y_train = np.eye(10)[y_train.astype('int32').flatten()]\n",
    "\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_test = np.eye(10)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section3の学習内容も踏まえて、CIFAR10のクラス分類を行いたいと思います。\n",
    "\n",
    "まず、モデルの作成を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 22:38:58.420409: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(120, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->120\n",
    "model.add(Dense(84, activation='relu', kernel_initializer='he_normal'))  # 120 ->84\n",
    "model.add(Dense(10, activation='softmax'))  # 84 ->10\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Section3で学習したDataAugumentationや画像データの正規化を学習に反映させてみます。\n",
    "\n",
    "kerasのImageDataGeneratorを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    horizontal_flip=True,  # 3.1.3 左右反転\n",
    "    # 3.2.1 Global Contrast Normalization (GCN) (Falseに設定しているのでここでは使用していない)\n",
    "    samplewise_center=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False)  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening (Falseに設定しているのでここでは使用していない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/3hjq04pn7ddfr_2j2g5f52c00000gn/T/ipykernel_36024/3786900849.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 17s 42ms/step - loss: 1.8623 - accuracy: 0.3176 - val_loss: 1.5899 - val_accuracy: 0.4258\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.6560 - accuracy: 0.3948 - val_loss: 1.5239 - val_accuracy: 0.4553\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.5770 - accuracy: 0.4272 - val_loss: 1.4667 - val_accuracy: 0.4764\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.5167 - accuracy: 0.4534 - val_loss: 1.3876 - val_accuracy: 0.5019\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.4771 - accuracy: 0.4664 - val_loss: 1.3001 - val_accuracy: 0.5410\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.4473 - accuracy: 0.4777 - val_loss: 1.3184 - val_accuracy: 0.5280\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.4167 - accuracy: 0.4911 - val_loss: 1.2743 - val_accuracy: 0.5446\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.3931 - accuracy: 0.4990 - val_loss: 1.2657 - val_accuracy: 0.5505\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.3700 - accuracy: 0.5064 - val_loss: 1.2679 - val_accuracy: 0.5447\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.3506 - accuracy: 0.5156 - val_loss: 1.2362 - val_accuracy: 0.5582\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.3332 - accuracy: 0.5215 - val_loss: 1.2562 - val_accuracy: 0.5533\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.3224 - accuracy: 0.5238 - val_loss: 1.2591 - val_accuracy: 0.5519\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.3080 - accuracy: 0.5293 - val_loss: 1.2119 - val_accuracy: 0.5665\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.2892 - accuracy: 0.5382 - val_loss: 1.1812 - val_accuracy: 0.5805\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.2850 - accuracy: 0.5408 - val_loss: 1.2014 - val_accuracy: 0.5749\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2721 - accuracy: 0.5431 - val_loss: 1.2384 - val_accuracy: 0.5551\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2593 - accuracy: 0.5490 - val_loss: 1.1802 - val_accuracy: 0.5837\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2556 - accuracy: 0.5489 - val_loss: 1.2385 - val_accuracy: 0.5658\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.2501 - accuracy: 0.5532 - val_loss: 1.2046 - val_accuracy: 0.5785\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.2444 - accuracy: 0.5555 - val_loss: 1.1953 - val_accuracy: 0.5775\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2239 - accuracy: 0.5605 - val_loss: 1.1489 - val_accuracy: 0.5951\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2214 - accuracy: 0.5637 - val_loss: 1.1557 - val_accuracy: 0.5918\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 17s 43ms/step - loss: 1.2160 - accuracy: 0.5642 - val_loss: 1.1733 - val_accuracy: 0.5912\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2169 - accuracy: 0.5648 - val_loss: 1.1707 - val_accuracy: 0.5908\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.2033 - accuracy: 0.5677 - val_loss: 1.1250 - val_accuracy: 0.6074\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.1962 - accuracy: 0.5708 - val_loss: 1.2123 - val_accuracy: 0.5716\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.1889 - accuracy: 0.5772 - val_loss: 1.1389 - val_accuracy: 0.5968\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.1933 - accuracy: 0.5749 - val_loss: 1.1653 - val_accuracy: 0.5909\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.1848 - accuracy: 0.5774 - val_loss: 1.0919 - val_accuracy: 0.6144\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 17s 41ms/step - loss: 1.1789 - accuracy: 0.5799 - val_loss: 1.1394 - val_accuracy: 0.6005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca21302650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
